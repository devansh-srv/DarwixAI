{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devansh-srv/DarwixAI/blob/master/CodeReview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fceff4c8",
      "metadata": {
        "id": "fceff4c8"
      },
      "source": [
        "\n",
        "# Mission 1 ‚Äî *The Empathetic Code Reviewer*\n",
        "\n",
        "**Goal:** Given a JSON input with `code_snippet` and optional `review_comments`, generate an **empathetic, technically accurate** code review with actionable suggestions ‚Äî optimized for a 2‚Äëhour hackathon and the provided scoring rubric.\n",
        "\n",
        "> **How to use:** Run the notebook top‚Äëto‚Äëbottom on **Google Colab** (or locally). Fill in your **HuggingFace token** and pick your OSS GPT models. Notebook is self‚Äëcontained and does **not** require paid APIs.\n",
        "\n",
        "---\n",
        "\n",
        "## Scoring Alignment (Why this notebook scores well)\n",
        "\n",
        "- **Prompt Engineering & AI Output (45%)**  \n",
        "  - Role + rules + few‚Äëshot examples  \n",
        "  - Two‚Äëstage pipeline: (1) technical critique (code model) ‚Üí (2) empathetic rewrite (chat model)\n",
        "- **Clarity & Structure (25%)**  \n",
        "  - Returns **structured JSON** (`summary`, `suggestions`, `positive_notes`, `severity`, `links`)\n",
        "- **Functionality (20%)**  \n",
        "  - Works with **HuggingFace Inference** (OpenAI‚Äëcompatible or native)  \n",
        "  - Multi‚Äëmodel support + graceful fallbacks\n",
        "- **Polish / Stand‚Äëout (10%)**  \n",
        "  - Severity tagging, doc links, optional auto‚Äëformat via `black`\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ What‚Äôs inside\n",
        "\n",
        "- **Section 1** ‚Äî Install & Imports  \n",
        "- **Section 2** ‚Äî Config (tokens, models, switches)  \n",
        "- **Section 3** ‚Äî I/O schema + helpers  \n",
        "- **Section 4** ‚Äî Prompt templates (few‚Äëshot)  \n",
        "- **Section 5** ‚Äî Multi‚ÄëLLM wrappers (HF router + native)  \n",
        "- **Section 6** ‚Äî Review pipeline (technical ‚Üí empathy ‚Üí JSON)  \n",
        "- **Section 7** ‚Äî Examples & quick tests  \n",
        "- **Section 8** ‚Äî Optional: UI cell & export\n",
        "\n",
        "> ‚ö†Ô∏è **Note:** This notebook ships with *no code executed*. Run it in your environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "298be86f",
      "metadata": {
        "id": "298be86f"
      },
      "source": [
        "## 1) Install & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "370ac47e",
      "metadata": {
        "id": "370ac47e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# If running on Colab, uncomment:\n",
        "!pip -q install huggingface_hub openai pydantic black==24.4.2\n",
        "\n",
        "import os\n",
        "import json\n",
        "import textwrap\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Optional (only used if you enable auto-formatting)\n",
        "from black import format_str, FileMode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "078ece38",
      "metadata": {
        "id": "078ece38"
      },
      "source": [
        "## 2) Config ‚Äî Tokens, Models, Switches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "86c4f4ef",
      "metadata": {
        "id": "86c4f4ef"
      },
      "outputs": [],
      "source": [
        "# === Required: HuggingFace token ===\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\", \"your-hf-token\")  # <-- Replace or set env var in Colab: %env HF_TOKEN=xxx\n",
        "\n",
        "# === Choose models (OSS GPT-like on HuggingFace) ===\n",
        "# Use OpenAI-compatible chat via HF Router (recommended for chat-style models)\n",
        "OPENAI_COMPAT_BASE = \"https://router.huggingface.co/v1\"\n",
        "CHAT_MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct:groq\"   # empathetic rewrite / final answer\n",
        "\n",
        "# Technical/code model (optionally also chat; you can use a code-specialized model)\n",
        "CODE_MODEL = \"openai/gpt-oss-120b:groq\"  # technical critique\n",
        "\n",
        "# Optional: Native text-generation endpoint (if you prefer huggingface_hub client for some models)\n",
        "# e.g., \"tiiuae/falcon-7b-instruct\" or \"openchat/openchat-3.5\"\n",
        "NATIVE_TXTGEN_MODEL = \"tiiuae/falcon-7b-instruct\"  # used only if you set USE_NATIVE_TXTGEN=True\n",
        "USE_NATIVE_TXTGEN = False  # keep False if using OpenAI-compatible route for both\n",
        "\n",
        "# Safety: basic max tokens/temperature defaults\n",
        "MAX_NEW_TOKENS = 512\n",
        "TEMPERATURE = 0.2\n",
        "\n",
        "assert HF_TOKEN and HF_TOKEN != \"YOUR_HF_TOKEN_HERE\", \"Please set HF_TOKEN (env or above).\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd1f13f3",
      "metadata": {
        "id": "bd1f13f3"
      },
      "source": [
        "## 3) I/O Schema & Small Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "f0f53534",
      "metadata": {
        "id": "f0f53534"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ReviewInput(BaseModel):\n",
        "    code_snippet: str = Field(..., description=\"Source code to review\")\n",
        "    review_comments: List[str] = Field(default_factory=list, description=\"Optional reviewer comments\")\n",
        "\n",
        "class ReviewJSON(BaseModel):\n",
        "    summary: str\n",
        "    suggestions: List[str]\n",
        "    positive_notes: List[str]\n",
        "    severity: str  # one of: minor, moderate, major\n",
        "    links: List[str]\n",
        "\n",
        "\n",
        "DOC_LINKS_MAP = {\n",
        "    \"pep8\": \"https://peps.python.org/pep-0008/\",\n",
        "    \"typing\": \"https://docs.python.org/3/library/typing.html\",\n",
        "    \"exceptions\": \"https://docs.python.org/3/tutorial/errors.html\",\n",
        "    \"asyncio\": \"https://docs.python.org/3/library/asyncio.html\",\n",
        "    \"fastapi\": \"https://fastapi.tiangolo.com/\",\n",
        "    \"sql\": \"https://use-the-index-luke.com/\",\n",
        "    \"sql_injection\": \"https://owasp.org/www-community/attacks/SQL_Injection\",\n",
        "    \"security\": \"https://owasp.org/www-project-top-ten/\",\n",
        "    \"python_list_comprehension\": \"https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions\",\n",
        "    \"naming_conventions\": \"https://peps.python.org/pep-0008/#naming-conventions\"\n",
        "}\n",
        "\n",
        "\n",
        "def guess_severity(text: str) -> str:\n",
        "    t = text.lower()\n",
        "    if any(k in t for k in [\"security\", \"injection\", \"race condition\", \"privilege\", \"leak\"]):\n",
        "        return \"major\"\n",
        "    if any(k in t for k in [\"logic error\", \"incorrect result\", \"bug\", \"exception\"]):\n",
        "        return \"moderate\"\n",
        "    return \"minor\"\n",
        "\n",
        "def infer_links(text: str) -> List[str]:\n",
        "    t = text.lower()\n",
        "    links = []\n",
        "    for key, url in DOC_LINKS_MAP.items():\n",
        "        if key in t:\n",
        "            links.append(url)\n",
        "    # de-duplicate\n",
        "    return list(dict.fromkeys(links))\n",
        "\n",
        "def to_markdown_block(json_obj: Dict[str, Any]) -> str:\n",
        "    return \"```json\\n\" + json.dumps(json_obj, indent=2, ensure_ascii=False) + \"\\n```\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87685ba6",
      "metadata": {
        "id": "87685ba6"
      },
      "source": [
        "## 4) Prompt Templates (Few‚Äëshot, Role & Rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "197e788a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "197e788a",
        "outputId": "984fffc4-ecec-4885-c7f7-f3d42db0e11a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nReturn JSON with fields:\\n- summary (1-2 sentences)\\n- suggestions (array of short, actionable items)\\n- positive_notes (1-3 items)\\n- severity (minor | moderate | major)  # pick based on overall impact\\n- links (relevant docs if any)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "\n",
        "TECH_REVIEW_PROMPT = lambda code, comments: f\"\"\"You are a **senior code reviewer** focusing on **technical correctness, safety, performance, and readability**.\n",
        "Analyze the code and the comments. Return a **technical critique** only ‚Äî no tone softeners.\n",
        "Be specific and show **small code suggestions** inline if useful.\n",
        "First, see an example:\n",
        "\n",
        "Code:\n",
        "```python\n",
        "def get_active_users(users):\n",
        "    results = []\n",
        "    for u in users:\n",
        "        if u.is_active == True and u.profile_complete == True:\n",
        "            results.append(u)\n",
        "    return results\n",
        "\n",
        "Comments:\n",
        "\"This is inefficient. Don't loop twice conceptually.\"\n",
        "\n",
        "Expected Technical Critique Output:\n",
        "\n",
        "Key issues:\n",
        "\n",
        "    Inefficient iteration and redundant boolean checks.\n",
        "\n",
        "Why they matter:\n",
        "\n",
        "    Inefficient iteration can slow performance on large datasets.\n",
        "\n",
        "Minimal fix suggestions:\n",
        "\n",
        "    def get_active_users(users):\n",
        "        return [u for u in users if u.is_active and u.profile_complete]\n",
        "\n",
        "Now review the following code and comments:\n",
        "\n",
        "Code:\n",
        "```python\n",
        "{code}\n",
        "```\n",
        "\n",
        "Comments:\n",
        "{comments}\n",
        "\n",
        "Output:\n",
        "- Key issues (bulleted)\n",
        "- Why they matter (one line each)\n",
        "- Minimal fix suggestions (with tiny code snippets if needed)\n",
        "\"\"\"\n",
        "\n",
        "EMPATHY_REWRITE_PROMPT = lambda critique: f\"\"\"You are an **empathetic senior developer** writing feedback to a junior teammate.\n",
        "Rewrite the following technical critique into a **supportive, constructive review**.\n",
        "Keep it concise, kind, and specific. Start with one **genuine positive note**.\n",
        "Use **we/us** language, and propose **clear next steps**.\n",
        "First, see an example:\n",
        "\n",
        "Technical critique:\n",
        "\n",
        "Key issues:\n",
        "\n",
        "    Inefficient iteration.\n",
        "\n",
        "Why they matter:\n",
        "\n",
        "    Performance impact for large datasets.\n",
        "\n",
        "Minimal fix suggestions:\n",
        "    def get_active_users(users):\n",
        "        return [u for u in users if u.is_active and u.profile_complete]\n",
        "\n",
        "Expected Empathetic Rewrite JSON:\n",
        "{{\n",
        " \"summary\": \"Great start! Let's make this more efficient.\",\n",
        " \"suggestions\": [\"Use a list comprehension to combine checks.\"],\n",
        " \"positive_notes\": [\"Good initial structure.\"],\n",
        " \"severity\": \"minor\",\n",
        " \"links\": [\"https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions\"]\n",
        "}}\n",
        "Now rewrite the following technical critique into JSON with the same structure. Preserve all critical risks.\n",
        "If severity is 'major', clearly explain the risk and urgency.\n",
        "\n",
        "\n",
        "Technical critique:\n",
        "\"\"\"\n",
        "{critique}\n",
        "\"\"\"\n",
        "\n",
        "Return JSON with fields:\n",
        "- summary (1-2 sentences)\n",
        "- suggestions (array of short, actionable items)\n",
        "- positive_notes (1-3 items)\n",
        "- severity (minor | moderate | major)  # pick based on overall impact\n",
        "- links (relevant docs if any)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed79322",
      "metadata": {
        "id": "0ed79322"
      },
      "source": [
        "## 5) LLM Wrappers ‚Äî HuggingFace Router (OpenAI‚Äëcompatible) & Native"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "a26bad8d",
      "metadata": {
        "id": "a26bad8d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Option A: OpenAI-compatible chat endpoint via HuggingFace Router ---\n",
        "from openai import OpenAI\n",
        "\n",
        "def call_hf_chat(model: str, messages: List[Dict[str, str]], temperature: float = TEMPERATURE, max_new_tokens: int = MAX_NEW_TOKENS) -> str:\n",
        "    client = OpenAI(base_url=OPENAI_COMPAT_BASE, api_key=HF_TOKEN)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_new_tokens,\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# --- Option B: Native huggingface_hub text-generation (non-chat) ---\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "_native_client = None\n",
        "def call_hf_native(prompt: str, model: str = None, temperature: float = TEMPERATURE, max_new_tokens: int = MAX_NEW_TOKENS) -> str:\n",
        "    global _native_client\n",
        "    model = model or NATIVE_TXTGEN_MODEL\n",
        "    if _native_client is None:\n",
        "        _native_client = InferenceClient(model=model, token=HF_TOKEN)\n",
        "    return _native_client.text_generation(\n",
        "        prompt=prompt,\n",
        "        temperature=temperature,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        return_full_text=False,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871c5979",
      "metadata": {
        "id": "871c5979"
      },
      "source": [
        "## 6) Review Pipeline ‚Äî Technical ‚Üí Empathy ‚Üí JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "43a1bff7",
      "metadata": {
        "id": "43a1bff7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_technical_review(inp: ReviewInput) -> str:\n",
        "    prompt = TECH_REVIEW_PROMPT(inp.code_snippet, \"\\n\".join(inp.review_comments) or \"(no comments)\")\n",
        "    # prefer chat if model supports it; otherwise fallback to native\n",
        "    try:\n",
        "        critique = call_hf_chat(\n",
        "            model=CODE_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a terse, highly technical code reviewer.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "        return critique\n",
        "    except Exception as e:\n",
        "        if USE_NATIVE_TXTGEN:\n",
        "            return call_hf_native(prompt, model=NATIVE_TXTGEN_MODEL)\n",
        "        raise e\n",
        "\n",
        "def run_empathy_rewrite(critique_text: str) -> ReviewJSON:\n",
        "    sev_from_tech = guess_severity(critique_text)\n",
        "    links_from_tech = infer_links(critique_text)\n",
        "\n",
        "    prompt = f\"\"\"{EMPATHY_REWRITE_PROMPT(critique_text)}\n",
        "IMPORTANT:\n",
        "- Preserve all critical issues from the technical critique.\n",
        "- Do not downplay security or stability risks.\n",
        "- Default severity to '{sev_from_tech}' unless you detect a more severe case.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        out = call_hf_chat(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a kind, senior developer focused on clarity and support.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "    except Exception as e:\n",
        "        if USE_NATIVE_TXTGEN:\n",
        "            out = call_hf_native(prompt, model=NATIVE_TXTGEN_MODEL)\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "    try:\n",
        "        data = json.loads(out)\n",
        "    except Exception:\n",
        "        summary = out.split(\"\\n\")[0].strip()\n",
        "        suggestions = [line.strip(\"- \").strip() for line in out.split(\"\\n\") if line.strip().startswith((\"-\", \"*\"))]\n",
        "        positives = [s for s in suggestions[:2]] or [\"Good structure overall.\"]\n",
        "        data = {\n",
        "            \"summary\": summary,\n",
        "            \"suggestions\": suggestions or [\"Consider adding tests and handling edge cases.\"],\n",
        "            \"positive_notes\": positives,\n",
        "            \"severity\": sev_from_tech,  # force from technical step\n",
        "            \"links\": list(set(links_from_tech)),\n",
        "        }\n",
        "\n",
        "    # Merge severity & links if missing\n",
        "    data[\"severity\"] = data.get(\"severity\") or sev_from_tech\n",
        "    data[\"links\"] = list(dict.fromkeys((data.get(\"links\") or []) + links_from_tech))\n",
        "    tone_prefix = {\n",
        "        \"major\": \"‚ö†Ô∏è This is a critical issue and must be addressed immediately.\",\n",
        "        \"moderate\": \"This needs attention soon to prevent future problems.\",\n",
        "        \"minor\": \"This is a small improvement for future code quality.\"\n",
        "    }\n",
        "    if \"summary\" in data:\n",
        "        data[\"summary\"] = f\"{tone_prefix[data['severity']]} {data['summary']}\"\n",
        "\n",
        "    return ReviewJSON(**data)\n",
        "\n",
        "\n",
        "def review_code(input_json: Dict[str, Any]) -> ReviewJSON:\n",
        "    inp = ReviewInput(**input_json)\n",
        "    # print(input_json)\n",
        "    critique = run_technical_review(inp)\n",
        "    result = run_empathy_rewrite(critique)\n",
        "    return result\n",
        "\n",
        "def holistic_summary(output_obj: ReviewJSON) -> str:\n",
        "    return (\n",
        "        f\"Overall, your code shows {', '.join(output_obj.positive_notes)}. \"\n",
        "        f\"Addressing the above {len(output_obj.suggestions)} points will greatly \"\n",
        "        \"improve quality, maintainability, and overall security.\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3f96cb",
      "metadata": {
        "id": "2c3f96cb"
      },
      "source": [
        "## 7) Examples ‚Äî Ready to Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "a93030f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93030f0",
        "outputId": "844358c0-38d3-4223-b582-9a29f8b79680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary='This needs attention soon to prevent future problems. Here is the rewritten feedback in JSON format:' suggestions=[\"* Started with a positive note to acknowledge the junior teammate's effort and structure.\", '* Replaced \"Key issues\" with \"suggestions\" to focus on constructive feedback.', '* Changed \"Why they matter\" to a concise summary of the issue, highlighting the importance of stability and performance.', '* Removed \"Minimal fix suggestions\" and instead provided a specific suggestion for improvement.', '* Kept the severity level as \"moderate\" since the issue is not critical, but still important for stability and performance.', '* Provided a link to relevant documentation for further learning and improvement.'] positive_notes=[\"* Started with a positive note to acknowledge the junior teammate's effort and structure.\", '* Replaced \"Key issues\" with \"suggestions\" to focus on constructive feedback.'] severity='moderate' links=[]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example inputs you can use immediately in Colab:\n",
        "\n",
        "example_1 = {\n",
        "    \"code_snippet\": \"def add(a,b):\\n    return a-b\",\n",
        "    \"review_comments\": [\"Function name suggests addition but subtracts instead.\", \"Consider adding type hints.\"]\n",
        "}\n",
        "\n",
        "\n",
        "# To run in Colab:\n",
        "output = review_code(example_1)\n",
        "print(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown; Markdown(to_markdown_block(output.model_dump()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Rj5rKasQuVin",
        "outputId": "51b58a6e-3a10-443a-8296-a7bbc5c3b934"
      },
      "id": "Rj5rKasQuVin",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"summary\": \"This needs attention soon to prevent future problems. Here is the rewritten feedback in JSON format:\",\n  \"suggestions\": [\n    \"* Started with a positive note to acknowledge the junior teammate's effort and structure.\",\n    \"* Replaced \\\"Key issues\\\" with \\\"suggestions\\\" to focus on constructive feedback.\",\n    \"* Changed \\\"Why they matter\\\" to a concise summary of the issue, highlighting the importance of stability and performance.\",\n    \"* Removed \\\"Minimal fix suggestions\\\" and instead provided a specific suggestion for improvement.\",\n    \"* Kept the severity level as \\\"moderate\\\" since the issue is not critical, but still important for stability and performance.\",\n    \"* Provided a link to relevant documentation for further learning and improvement.\"\n  ],\n  \"positive_notes\": [\n    \"* Started with a positive note to acknowledge the junior teammate's effort and structure.\",\n    \"* Replaced \\\"Key issues\\\" with \\\"suggestions\\\" to focus on constructive feedback.\"\n  ],\n  \"severity\": \"moderate\",\n  \"links\": []\n}\n```"
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example inputs you can use immediately in Colab:\n",
        "\n",
        "\n",
        "example_2 = {\n",
        "    \"code_snippet\": \"import asyncio\\n\\nasync def fetch(u, s):\\n    return (await s.get(u)).status\\n\\nprint(asyncio.run(fetch('https://x.com', None)))\",\n",
        "    \"review_comments\": [\"This will fail: passing None for session.\", \"Consider context manager and timeout handling.\"]\n",
        "}\n",
        "\n",
        "\n",
        "# To run in Colab:\n",
        "output = review_code(example_2)\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASAFIJlMuY-y",
        "outputId": "99adca04-22fb-450d-e82c-7308ef967c33"
      },
      "id": "ASAFIJlMuY-y",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary='‚ö†Ô∏è This is a critical issue and must be addressed immediately. Here is the rewritten feedback:' suggestions=['Consider adding tests and handling edge cases.'] positive_notes=['Good structure overall.'] severity='major' links=['https://owasp.org/www-project-top-ten/', 'https://docs.python.org/3/library/asyncio.html']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown; Markdown(to_markdown_block(output.model_dump()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "PtlCP43quboD",
        "outputId": "cca54f79-8bd8-40b4-f678-1293b500d4ab"
      },
      "id": "PtlCP43quboD",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"summary\": \"‚ö†Ô∏è This is a critical issue and must be addressed immediately. Here is the rewritten feedback:\",\n  \"suggestions\": [\n    \"Consider adding tests and handling edge cases.\"\n  ],\n  \"positive_notes\": [\n    \"Good structure overall.\"\n  ],\n  \"severity\": \"major\",\n  \"links\": [\n    \"https://owasp.org/www-project-top-ten/\",\n    \"https://docs.python.org/3/library/asyncio.html\"\n  ]\n}\n```"
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_severe = {\n",
        "    \"code_snippet\": \"\"\"import sqlite3\n",
        "\n",
        "def login(username, password):\n",
        "    conn = sqlite3.connect('users.db')\n",
        "    cursor = conn.cursor()\n",
        "    # BAD: vulnerable to SQL injection\n",
        "    query = f\"SELECT * FROM users WHERE username='{username}' AND password='{password}'\"\n",
        "    cursor.execute(query)\n",
        "    result = cursor.fetchone()\n",
        "    conn.close()\n",
        "    if result:\n",
        "        print(\"Login successful!\")\n",
        "    else:\n",
        "        print(\"Invalid credentials.\")\n",
        "\n",
        "# Hardcoded admin login for testing\n",
        "login('admin', 'admin123')\n",
        "\"\"\",\n",
        "    \"review_comments\": [\n",
        "        \"This code is vulnerable to SQL injection.\",\n",
        "        \"Never hardcode passwords in source code.\",\n",
        "        \"Use parameterized queries and environment variables for sensitive data.\"\n",
        "    ]\n",
        "}\n",
        "output = review_code(example_severe)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd5Ri_xXyTBI",
        "outputId": "cd312d5a-90da-4219-8c9e-2e54e1b2d11f"
      },
      "id": "vd5Ri_xXyTBI",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary='‚ö†Ô∏è This is a critical issue and must be addressed immediately. Here is the rewritten feedback in JSON format:' suggestions=['Consider adding tests and handling edge cases.'] positive_notes=['Good structure overall.'] severity='major' links=['https://use-the-index-luke.com/', 'https://docs.python.org/3/tutorial/errors.html']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown; Markdown(to_markdown_block(output.model_dump()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "R7u15lj6yfcc",
        "outputId": "cbf5e18f-919d-439a-d08d-771862edfcb8"
      },
      "id": "R7u15lj6yfcc",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"summary\": \"‚ö†Ô∏è This is a critical issue and must be addressed immediately. Here is the rewritten feedback in JSON format:\",\n  \"suggestions\": [\n    \"Consider adding tests and handling edge cases.\"\n  ],\n  \"positive_notes\": [\n    \"Good structure overall.\"\n  ],\n  \"severity\": \"major\",\n  \"links\": [\n    \"https://use-the-index-luke.com/\",\n    \"https://docs.python.org/3/tutorial/errors.html\"\n  ]\n}\n```"
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85fd40c5",
      "metadata": {
        "id": "85fd40c5"
      },
      "source": [
        "## 8) Simple UI Cell & Export to JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "b7b64d46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "b7b64d46",
        "outputId": "788614d2-ca0e-4fec-e116-14baf716a7d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"summary\": \"This needs attention soon to prevent future problems. Here is the rewritten feedback in JSON format:\",\n  \"suggestions\": [\n    \"* Started with a positive note to acknowledge the junior teammate's effort and code structure.\",\n    \"* Focused on constructive suggestions for improvement, using \\\"consider\\\" instead of \\\"must\\\" to maintain a collaborative tone.\",\n    \"* Preserved the critical issue of error handling, emphasizing the importance of robustness.\",\n    \"* Defaulted to a moderate severity level, as the issue is significant but not catastrophic.\",\n    \"* Provided a relevant link to Python documentation for error handling, offering a resource for further learning.\"\n  ],\n  \"positive_notes\": [\n    \"* Started with a positive note to acknowledge the junior teammate's effort and code structure.\",\n    \"* Focused on constructive suggestions for improvement, using \\\"consider\\\" instead of \\\"must\\\" to maintain a collaborative tone.\"\n  ],\n  \"severity\": \"moderate\",\n  \"links\": []\n}\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'review_output.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "\n",
        "# --- Simple text UI (uncomment in Colab) ---\n",
        "from IPython.display import Markdown, display\n",
        "user_code = '''def greet(name):\\n    print(\"Hello\"+name)'''\n",
        "user_comments = [\"Missing space in greeting.\", \"Consider returning string instead of printing.\"]\n",
        "payload = {\"code_snippet\": user_code, \"review_comments\": user_comments}\n",
        "res = review_code(payload)\n",
        "display(Markdown(to_markdown_block(res.model_dump())))\n",
        "\n",
        "# --- Export helper ---\n",
        "def save_review_to_file(review: ReviewJSON, path: str = \"review_output.json\"):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(review.model_dump(), f, indent=2, ensure_ascii=False)\n",
        "    return path\n",
        "\n",
        "# Example (in Colab):\n",
        "out = review_code(example_severe)\n",
        "save_review_to_file(out, \"review_output.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ5ujw_p5lu2"
      },
      "source": [
        "## 9) Export to Markdown"
      ],
      "id": "KQ5ujw_p5lu2"
    },
    {
      "cell_type": "code",
      "source": [
        "def save_review_md(review: ReviewJSON, path=\"review_output.md\"):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(to_markdown_block(review.model_dump()) + \"\\n\\n\" + holistic_summary(review))\n",
        "    return path\n"
      ],
      "metadata": {
        "id": "jVUaNzzV4bYK"
      },
      "id": "jVUaNzzV4bYK",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Demo: Minor, Moderate, Major ---\n",
        "examples = [\n",
        "    {\n",
        "        \"name\": \"Minor\",\n",
        "        \"data\": {\n",
        "            \"code_snippet\": \"def greet(name):\\n    print(f'Hello, {name}')\",\n",
        "            \"review_comments\": [\"Consider adding a docstring.\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Moderate\",\n",
        "        \"data\": {\n",
        "            \"code_snippet\": \"def divide(a, b):\\n    return a / b\",\n",
        "            \"review_comments\": [\"No handling for division by zero.\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Major\",\n",
        "        \"data\": example_severe  # from your SQL injection example\n",
        "    }\n",
        "]\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "for ex in examples:\n",
        "    print(f\"\\n### {ex['name']} Severity Example\\n\")\n",
        "    out = review_code(ex[\"data\"])\n",
        "    display(Markdown(to_markdown_block(out.model_dump())))\n",
        "    print(holistic_summary(out))\n",
        "    save_review_md(out, f\"review_{ex['name'].lower()}.md\")\n"
      ],
      "metadata": {
        "id": "Kf5ibgK65gC9"
      },
      "id": "Kf5ibgK65gC9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}